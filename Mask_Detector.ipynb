{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask Detector.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMrRMJK57Bj+B5ZX9dV4hfM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ihtishamargan/Face-Mask-Detection-DL/blob/main/Mask_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAHpRDQKeSRZ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtk_X7Nsm_s-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "614HaKMv28Lz"
      },
      "source": [
        "!unrar x \"/content/gdrive/My Drive/Face-Mask-Detector/data/self-built-masked-face-recognition-dataset.rar\" \"/content/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYdIT7y6kZ72"
      },
      "source": [
        "!pip install pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwbzY8XvxXWy"
      },
      "source": [
        "# Adding images into a pandas Dataframe and saving it as csv file\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "datasetPath = Path('/content/self-built-masked-face-recognition-dataset')\n",
        "maskPath = datasetPath/'AFDB_masked_face_dataset'\n",
        "nonMaskPath = datasetPath/'AFDB_face_dataset'\n",
        "maskDF = pd.DataFrame()\n",
        "# images with mask\n",
        "for subject in tqdm(list(maskPath.iterdir()), desc='mask photos'):\n",
        "    for imgPath in subject.iterdir():\n",
        "        maskDF = maskDF.append({\n",
        "            'image': str(imgPath),\n",
        "            'mask': 1\n",
        "        }, ignore_index=True)\n",
        "\n",
        "        \n",
        "#images without mask        \n",
        "for subject in tqdm(list(nonMaskPath.iterdir()), desc='non mask photos'):\n",
        "    for imgPath in subject.iterdir():\n",
        "        maskDF = maskDF.append({\n",
        "            'image': str(imgPath),\n",
        "            'mask': 0\n",
        "        }, ignore_index=True)\n",
        "\n",
        "dfName = '/content/gdrive/My Drive/Face-Mask-Detector/data/mask_df.csv'\n",
        "print(f'saving Dataframe to: {dfName}')\n",
        "maskDF.to_csv(dfName)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGH8ACRz4U_H"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2itCmNYWxj7Z"
      },
      "source": [
        "\"\"\" Dataset module\n",
        "\"\"\"\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torch import long, tensor\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision.transforms import Compose, Resize, ToPILImage, ToTensor\n",
        "\n",
        "\n",
        "class MaskDataset(Dataset):\n",
        "    \"\"\" Masked faces dataset\n",
        "        0 = 'no mask'\n",
        "        1 = 'mask'\n",
        "    \"\"\"\n",
        "    def __init__(self, dataFrame):\n",
        "        self.dataFrame = dataFrame\n",
        "        \n",
        "        self.transformations = Compose([\n",
        "            ToPILImage(),\n",
        "            Resize((100, 100)),\n",
        "            ToTensor(), # [0, 1]\n",
        "        ])\n",
        "    \n",
        "    def __getitem__(self, key):\n",
        "        if isinstance(key, slice):\n",
        "            raise NotImplementedError('slicing is not supported')\n",
        "        \n",
        "        row = self.dataFrame.iloc[key]\n",
        "        image = cv2.imdecode(np.fromfile(row['image'], dtype=np.uint8),\n",
        "                             cv2.IMREAD_UNCHANGED)\n",
        "        return {\n",
        "            'image': self.transformations(image),\n",
        "            'mask': tensor([row['mask']], dtype=long), # pylint: disable=not-callable\n",
        "        }\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataFrame.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akr4-1wPh1Pl"
      },
      "source": [
        "from pathlib import Path\n",
        "from typing import Dict, List\n",
        "import torch\n",
        "import pandas as pd\n",
        "import pytorch_lightning as pl\n",
        "import torch.nn.init as init\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.metrics import Accuracy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import Tensor\n",
        "from torch.nn import (Conv2d, CrossEntropyLoss, Linear, MaxPool2d, ReLU,\n",
        "                      Sequential)\n",
        "from torch.optim import Adam\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from torch.utils.data import DataLoader\n",
        "#from torch.utils.data.dataset import MaskDataset\n",
        "#from data.dataset import MaskDataset\n",
        "\n",
        "\n",
        "class MaskDetector(pl.LightningModule):\n",
        "    \"\"\" MaskDetector PyTorch Lightning class\n",
        "    \"\"\"\n",
        "    def __init__(self, maskDFPath: Path=None):\n",
        "        super(MaskDetector, self).__init__()\n",
        "        self.maskDFPath = maskDFPath\n",
        "        \n",
        "        self.maskDF = None\n",
        "        self.trainDF = None\n",
        "        self.validateDF = None\n",
        "        self.crossEntropyLoss = None\n",
        "        self.learningRate = 0.00001\n",
        "        \n",
        "        self.trainAcc = Accuracy()\n",
        "        self.valAcc = Accuracy()\n",
        "        \n",
        "        self.convLayer1 = convLayer1 = Sequential(\n",
        "            Conv2d(3, 32, kernel_size=(3, 3), padding=(1, 1)),\n",
        "            ReLU(),\n",
        "            MaxPool2d(kernel_size=(2, 2))\n",
        "        )\n",
        "        \n",
        "        self.convLayer2 = convLayer2 = Sequential(\n",
        "            Conv2d(32, 64, kernel_size=(3, 3), padding=(1, 1)),\n",
        "            ReLU(),\n",
        "            MaxPool2d(kernel_size=(2, 2))\n",
        "        )\n",
        "        \n",
        "        self.convLayer3 = convLayer3 = Sequential(\n",
        "            Conv2d(64, 128, kernel_size=(3, 3), padding=(1, 1), stride=(3,3)),\n",
        "            ReLU(),\n",
        "            MaxPool2d(kernel_size=(2, 2))\n",
        "        )\n",
        "        \n",
        "        self.linearLayers = linearLayers = Sequential(\n",
        "            Linear(in_features=2048, out_features=1024),\n",
        "            ReLU(),\n",
        "            Linear(in_features=1024, out_features=2),\n",
        "        )\n",
        "        \n",
        "        # Initialize layers' weights\n",
        "        for sequential in [convLayer1, convLayer2, convLayer3, linearLayers]:\n",
        "            for layer in sequential.children():\n",
        "                if isinstance(layer, (Linear, Conv2d)):\n",
        "                    init.xavier_uniform_(layer.weight)\n",
        "    \n",
        "    def forward(self, x: Tensor): # pylint: disable=arguments-differ\n",
        "        \"\"\" forward pass\n",
        "        \"\"\"\n",
        "        out = self.convLayer1(x)\n",
        "        out = self.convLayer2(out)\n",
        "        out = self.convLayer3(out)\n",
        "        out = out.view(-1, 2048)\n",
        "        out = self.linearLayers(out)\n",
        "        return out\n",
        "    \n",
        "    def prepare_data(self) -> None:\n",
        "        self.maskDF = maskDF = pd.read_csv(self.maskDFPath)\n",
        "        train, validate = train_test_split(maskDF, test_size=0.3, random_state=0,\n",
        "                                           stratify=maskDF['mask'])\n",
        "        self.trainDF = MaskDataset(train)\n",
        "        self.validateDF = MaskDataset(validate)\n",
        "        \n",
        "        # Create weight vector for CrossEntropyLoss\n",
        "        maskNum = maskDF[maskDF['mask']==1].shape[0]\n",
        "        nonMaskNum = maskDF[maskDF['mask']==0].shape[0]\n",
        "        nSamples = [nonMaskNum, maskNum]\n",
        "        normedWeights = [1 - (x / sum(nSamples)) for x in nSamples]\n",
        "        self.crossEntropyLoss = CrossEntropyLoss(weight=torch.tensor(normedWeights))\n",
        "    \n",
        "    def train_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(self.trainDF, batch_size=32, shuffle=True, num_workers=2)\n",
        "    \n",
        "    def val_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(self.validateDF, batch_size=32, num_workers=2)\n",
        "    \n",
        "    def configure_optimizers(self) -> Optimizer:\n",
        "        return Adam(self.parameters(), lr=self.learningRate)\n",
        "    \n",
        "    # pylint: disable=arguments-differ\n",
        "    def training_step(self, batch: dict, _batch_idx: int) -> Tensor:\n",
        "        inputs, labels = batch['image'], batch['mask']\n",
        "        labels = labels.flatten()\n",
        "        outputs = self.forward(inputs)\n",
        "        loss = self.crossEntropyLoss(outputs, labels)\n",
        "        self.trainAcc(outputs.argmax(dim=1), labels)\n",
        "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=False)\n",
        "        return loss\n",
        "    \n",
        "    def training_epoch_end(self, _trainingStepOutputs):\n",
        "        self.log('train_acc', self.trainAcc.compute() * 100, prog_bar=True)\n",
        "        self.trainAcc.reset()\n",
        "    \n",
        "    def validation_step(self, batch: dict, _batch_idx: int) -> Dict[str, Tensor]:\n",
        "        inputs, labels = batch['image'], batch['mask']\n",
        "        labels = labels.flatten()\n",
        "        outputs = self.forward(inputs)\n",
        "        loss = self.crossEntropyLoss(outputs, labels)\n",
        "        \n",
        "        self.valAcc(outputs.argmax(dim=1), labels)\n",
        "        \n",
        "        return {'val_loss': loss}\n",
        "    \n",
        "    def validation_epoch_end(self, validationStepOutputs: List[Dict[str, Tensor]]):\n",
        "        avgLoss = torch.stack([x['val_loss'] for x in validationStepOutputs]).mean()\n",
        "        valAcc = self.valAcc.compute() * 100\n",
        "        self.valAcc.reset()\n",
        "        self.log('val_loss', avgLoss, prog_bar=True)\n",
        "        self.log('val_acc', valAcc, prog_bar=True)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = MaskDetector(Path('/content/gdrive/My Drive/Face-Mask-Detector/data/mask_df.csv'))\n",
        "    logger = TensorBoardLogger(\"/content/gdrive/My Drive/Face-Mask-Detector/tensorboard\", name=\"mask-detector\")\n",
        "    checkpointCallback = ModelCheckpoint(\n",
        "        filename='{epoch}-{val_loss:.2f}-{val_acc:.2f}',\n",
        "        verbose=True,\n",
        "        monitor='val_acc',\n",
        "        mode='max'\n",
        "    )\n",
        "    trainer = Trainer(gpus=1 if torch.cuda.is_available() else 0,\n",
        "                      max_epochs=10,\n",
        "                      logger=logger,\n",
        "                      checkpoint_callback=checkpointCallback)\n",
        "    trainer.fit(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCzeCUw1mEdW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}